{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed5af1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb59d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"/Users/abdullahyehia/Desktop/data/creditcard.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10beedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ba56646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bef2d16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for nulls\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62fca2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for dupes\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b248048e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0a47c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b0c81b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    283253\n",
      "1       473\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['Class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3087b0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V20       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...  0.524980  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#minority class are 0.7% from the total data.\n",
    "x= data.drop(columns=['Class'])\n",
    "y= data['Class']\n",
    "x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76bbfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# splittin so we could resample , choose best features.\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40904a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    226602\n",
      "1       378\n",
      "Name: count, dtype: int64\n",
      "Class\n",
      "0    56651\n",
      "1       95\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "#a huge imbalance but each the train and test has nearly the same percent of minority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa4a4c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scalling data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scalled = scaler.fit_transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cb92fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying smote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbe3aa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42) # Initialize SMOTE, random_state for reproducibility\n",
    "X_train_resampled_SMOTE, y_train_resampled_SMOTE = smote.fit_resample(X_train_scalled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4aaaaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    226602\n",
      "1    226602\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_resampled_SMOTE.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "963665dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_resampled_SMOTE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fc69b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying under sampling.\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rUS = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "X_train_resampled_rus, y_train_resampled_rus= rUS.fit_resample(X_train_scalled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c97555db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    378\n",
      "1    378\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train_resampled_rus.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d63c1a",
   "metadata": {},
   "source": [
    "Up until now there is two options : X_train_resampled_rus, y_train_resampled_rus this is undersampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec72c2d",
   "metadata": {},
   "source": [
    "X_train_resampled_SMOTE, y_train_resampled_SMOTE this is using SMOTE overSampling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c3b6257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features for rus sampling :  [False False False  True  True False False  True  True  True  True  True\n",
      "  True False  True  True  True  True  True  True  True False False False\n",
      " False False False False False False]\n",
      "the columns are:     Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "\n",
      "         V8        V9  ...       V20       V21       V22       V23       V24  \\\n",
      "0  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474  0.066928   \n",
      "\n",
      "        V25       V26       V27       V28  Amount  \n",
      "0  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
      "\n",
      "[1 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Base model for RFE\n",
    "base_model = RandomForestClassifier(\n",
    "    n_estimators=200,          # Enough trees for stability\n",
    "    max_depth=None,            # Let trees grow until stopping criteria\n",
    "    min_samples_split=2,\n",
    "    class_weight='balanced',   # Handle imbalance, even though you resampled\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Recursive Feature Elimination\n",
    "selector = RFE(\n",
    "    estimator=base_model,\n",
    "    n_features_to_select=15,   # Try starting with ~50% of your features\n",
    "    step=1\n",
    ")\n",
    "\n",
    "\n",
    "selector.fit(X_train_resampled_rus, y_train_resampled_rus)\n",
    "selected_features_rus = selector.support_\n",
    "type(selector.support_)\n",
    "print(\"Selected Features for rus sampling : \", selected_features_rus)\n",
    "print('the columns are: ',x.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5b6958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating over a 1D array:\n",
      "[4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "print(\"Iterating over a 1D array:\")\n",
    "choosen_Feat_rus=[]\n",
    "i=0\n",
    "for index, value in np.ndenumerate(selected_features_rus):\n",
    "    #print(f\"Index: {index}, Value: {value}\")\n",
    "    if value == True :\n",
    "        choosen_Feat_rus.append( i+1)\n",
    "    i += 1\n",
    "print(choosen_Feat_rus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b5e60f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features for sMOTE sampling: [False False  True  True  True False False  True  True  True  True  True\n",
      "  True False  True False  True  True  True  True False False False False\n",
      " False False  True False False False]\n"
     ]
    }
   ],
   "source": [
    "selector.fit(X_train_resampled_SMOTE, y_train_resampled_SMOTE)\n",
    "selected_features_SMOTE = selector.support_\n",
    "print(\"Selected Features for sMOTE sampling:\", selected_features_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba15081d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 27]\n"
     ]
    }
   ],
   "source": [
    "choosen_Feat_smote=[]\n",
    "i=1\n",
    "for index, value in np.ndenumerate(selected_features_SMOTE):\n",
    "    #print(f\"Index: {index}, Value: {value}\")\n",
    "    if value == True :\n",
    "        choosen_Feat_smote.append(i)\n",
    "    i += 1\n",
    "print(choosen_Feat_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3da3bb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features for only scaled: [False False False  True  True  True False  True  True False  True  True\n",
      "  True False  True False  True  True  True  True  True False False False\n",
      " False False False False False  True]\n",
      "[4, 5, 6, 8, 9, 11, 12, 13, 15, 17, 18, 19, 20, 21, 30]\n"
     ]
    }
   ],
   "source": [
    "selector.fit(X_train_scalled, y_train)\n",
    "selected_features_scaled = selector.support_\n",
    "print(\"Selected Features for only scaled:\", selected_features_scaled)\n",
    "choosen_Feat_scaled=[]\n",
    "i=1\n",
    "for index, value in np.ndenumerate(selected_features_scaled):\n",
    "    #print(f\"Index: {index}, Value: {value}\")\n",
    "    if value == True :\n",
    "        choosen_Feat_scaled.append(i)\n",
    "    i += 1\n",
    "print(choosen_Feat_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235444df",
   "metadata": {},
   "source": [
    "random forest with undersampled data (low scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "338ca649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for RUS:\n",
      "[[55726   925]\n",
      " [   13    82]]\n",
      "Classification Report for RUS:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56651\n",
      "           1       0.08      0.86      0.15        95\n",
      "\n",
      "    accuracy                           0.98     56746\n",
      "   macro avg       0.54      0.92      0.57     56746\n",
      "weighted avg       1.00      0.98      0.99     56746\n",
      "\n",
      "Accuracy for RUS: 0.9834702005427696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=200)\n",
    "model.fit(X_train_resampled_rus, y_train_resampled_rus)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "y_pred_rus = model.predict(X_test_scaled)\n",
    "print(\"Confusion Matrix for RUS:\")\n",
    "print(confusion_matrix(y_test, y_pred_rus))\n",
    "print(\"Classification Report for RUS:\")\n",
    "print(classification_report(y_test, y_pred_rus))\n",
    "print(\"Accuracy for RUS:\", accuracy_score(y_test, y_pred_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbc7f366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abdullahyehia/Desktop/NTI-Project/Credit-Card-Fraud_Detection/tf-env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f92ea70",
   "metadata": {},
   "source": [
    "trying to use optuna to tune hyperparametrs. best was 0.84 f1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e47db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 01:27:09,436] A new study created in memory with name: no-name-0ee19184-8c20-4b7b-a2c2-3c65673fb46d\n",
      "[I 2025-08-11 01:27:15,248] Trial 0 finished with value: 0.8279569892473119 and parameters: {'lambda': 1.0314830379008808, 'alpha': 4.0276103559652574e-11, 'max_depth': 23, 'eta': 0.3076650634730445, 'subsample': 0.5636525390752428, 'colsample_bytree': 0.7547202446104054, 'min_child_weight': 1, 'scale_pos_weight': 2.103012257246482}. Best is trial 0 with value: 0.8279569892473119.\n",
      "[I 2025-08-11 01:27:20,758] Trial 1 finished with value: 0.7731958762886598 and parameters: {'lambda': 1.728609724947462, 'alpha': 0.0005572606614614708, 'max_depth': 30, 'eta': 0.42360661329430715, 'subsample': 0.5440358617213427, 'colsample_bytree': 0.9796388238094185, 'min_child_weight': 2, 'scale_pos_weight': 7.893322020556086}. Best is trial 0 with value: 0.8279569892473119.\n",
      "[I 2025-08-11 01:27:25,540] Trial 2 finished with value: 0.8105263157894737 and parameters: {'lambda': 1.8296593661226996, 'alpha': 1.1412820729017543e-07, 'max_depth': 23, 'eta': 0.5605971938375169, 'subsample': 0.682817332007986, 'colsample_bytree': 0.6767326093700949, 'min_child_weight': 1, 'scale_pos_weight': 5.443331200438277}. Best is trial 0 with value: 0.8279569892473119.\n",
      "[I 2025-08-11 01:27:31,047] Trial 3 finished with value: 0.806282722513089 and parameters: {'lambda': 0.6403394783504484, 'alpha': 3.0293638329124383e-09, 'max_depth': 23, 'eta': 0.2105923949045299, 'subsample': 0.6152217403074254, 'colsample_bytree': 0.6018792406896301, 'min_child_weight': 2, 'scale_pos_weight': 2.626954896220348}. Best is trial 0 with value: 0.8279569892473119.\n",
      "[I 2025-08-11 01:27:35,298] Trial 4 finished with value: 0.806282722513089 and parameters: {'lambda': 1.3499626963634201, 'alpha': 7.587162726118931e-10, 'max_depth': 21, 'eta': 0.3959707808881176, 'subsample': 0.6446206368495553, 'colsample_bytree': 0.8674996305135991, 'min_child_weight': 1, 'scale_pos_weight': 2.618733214312003}. Best is trial 0 with value: 0.8279569892473119.\n",
      "[I 2025-08-11 01:27:38,871] Trial 5 finished with value: 0.8369565217391305 and parameters: {'lambda': 1.673869601699245, 'alpha': 1.2402563256310973e-09, 'max_depth': 29, 'eta': 0.5428649530044583, 'subsample': 0.6599376010764699, 'colsample_bytree': 0.7463945358189935, 'min_child_weight': 1, 'scale_pos_weight': 2.2841803766951783}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:27:42,430] Trial 6 finished with value: 0.7936507936507936 and parameters: {'lambda': 1.949277478365764, 'alpha': 7.685209815757474e-05, 'max_depth': 30, 'eta': 0.5860443283767364, 'subsample': 0.5906491910975045, 'colsample_bytree': 0.745724948139681, 'min_child_weight': 2, 'scale_pos_weight': 4.10434689386731}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:27:47,627] Trial 7 finished with value: 0.7875647668393783 and parameters: {'lambda': 1.716822885907303, 'alpha': 2.3444686914315855e-06, 'max_depth': 23, 'eta': 0.2551494626881907, 'subsample': 0.7869812558885008, 'colsample_bytree': 0.9822291537830165, 'min_child_weight': 2, 'scale_pos_weight': 5.244581835724718}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:27:53,129] Trial 8 finished with value: 0.8253968253968254 and parameters: {'lambda': 0.539041067288841, 'alpha': 2.3772781515964846e-11, 'max_depth': 24, 'eta': 0.21506783705486698, 'subsample': 0.7412021837689821, 'colsample_bytree': 0.6049498813910622, 'min_child_weight': 1, 'scale_pos_weight': 2.9789348144199157}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:27:58,910] Trial 9 finished with value: 0.8191489361702128 and parameters: {'lambda': 0.5952772192133521, 'alpha': 2.7409097704295757e-11, 'max_depth': 27, 'eta': 0.22221010021980417, 'subsample': 0.5029524663965272, 'colsample_bytree': 0.6482384193068884, 'min_child_weight': 1, 'scale_pos_weight': 2.268557848519978}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:02,357] Trial 10 finished with value: 0.8191489361702128 and parameters: {'lambda': 1.36418993599515, 'alpha': 0.18922656044108654, 'max_depth': 27, 'eta': 0.6941738123041218, 'subsample': 0.6990802719196767, 'colsample_bytree': 0.5082739231193765, 'min_child_weight': 1, 'scale_pos_weight': 1.0542056261234913}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:06,975] Trial 11 finished with value: 0.8306010928961749 and parameters: {'lambda': 0.955670236044817, 'alpha': 7.870523943642743e-09, 'max_depth': 20, 'eta': 0.30409405362362774, 'subsample': 0.5751466936049645, 'colsample_bytree': 0.8065137299505463, 'min_child_weight': 1, 'scale_pos_weight': 1.05594727549097}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:11,236] Trial 12 finished with value: 0.8172043010752689 and parameters: {'lambda': 1.0339293761147494, 'alpha': 3.737661276908848e-08, 'max_depth': 20, 'eta': 0.3154998238365275, 'subsample': 0.6403907490388828, 'colsample_bytree': 0.8428147573265394, 'min_child_weight': 1, 'scale_pos_weight': 1.0711712469596213}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:15,394] Trial 13 finished with value: 0.806282722513089 and parameters: {'lambda': 0.9803853371268543, 'alpha': 5.9315325606606505e-09, 'max_depth': 27, 'eta': 0.46410520637610625, 'subsample': 0.6939532795758839, 'colsample_bytree': 0.8377396486229762, 'min_child_weight': 1, 'scale_pos_weight': 3.471336415730513}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:21,171] Trial 14 finished with value: 0.8324324324324325 and parameters: {'lambda': 0.8163039886914747, 'alpha': 2.3508082132401866e-07, 'max_depth': 26, 'eta': 0.3232308794039077, 'subsample': 0.5824372387085976, 'colsample_bytree': 0.7563418213239034, 'min_child_weight': 1, 'scale_pos_weight': 1.5802020030375217}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:24,990] Trial 15 finished with value: 0.8 and parameters: {'lambda': 1.5672910409793621, 'alpha': 1.6488986691035739e-06, 'max_depth': 29, 'eta': 0.49094212184617936, 'subsample': 0.5218261565949897, 'colsample_bytree': 0.7428450540026417, 'min_child_weight': 1, 'scale_pos_weight': 4.184618358115146}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:29,224] Trial 16 finished with value: 0.7979274611398963 and parameters: {'lambda': 0.7706810153000774, 'alpha': 0.00020897519482543554, 'max_depth': 26, 'eta': 0.35363343737784175, 'subsample': 0.6115753943125112, 'colsample_bytree': 0.910518590061472, 'min_child_weight': 1, 'scale_pos_weight': 1.7636122144688648}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:32,616] Trial 17 finished with value: 0.806282722513089 and parameters: {'lambda': 1.2121961094953688, 'alpha': 2.8089581525949923e-07, 'max_depth': 28, 'eta': 0.6884803522849963, 'subsample': 0.7268381224310535, 'colsample_bytree': 0.6835513184123534, 'min_child_weight': 2, 'scale_pos_weight': 6.4189737923124195}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:37,631] Trial 18 finished with value: 0.8148148148148148 and parameters: {'lambda': 1.5473264861933629, 'alpha': 0.013708550460759734, 'max_depth': 25, 'eta': 0.26672784555616846, 'subsample': 0.6590455122791474, 'colsample_bytree': 0.7954734301640435, 'min_child_weight': 1, 'scale_pos_weight': 3.441478611911389}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:41,794] Trial 19 finished with value: 0.8235294117647058 and parameters: {'lambda': 0.7962474516544589, 'alpha': 1.9909758337986802e-05, 'max_depth': 29, 'eta': 0.34292144734686686, 'subsample': 0.6141938864878621, 'colsample_bytree': 0.8959785063834489, 'min_child_weight': 1, 'scale_pos_weight': 1.8328031640175204}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:46,049] Trial 20 finished with value: 0.8306010928961749 and parameters: {'lambda': 1.2540593623102119, 'alpha': 2.806981567114508e-10, 'max_depth': 25, 'eta': 0.5399112263686585, 'subsample': 0.7875767552764545, 'colsample_bytree': 0.5225393491228538, 'min_child_weight': 2, 'scale_pos_weight': 5.514691296866472}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:51,125] Trial 21 finished with value: 0.7936507936507936 and parameters: {'lambda': 0.8795366848749988, 'alpha': 1.4360289302471284e-08, 'max_depth': 21, 'eta': 0.3061464943975009, 'subsample': 0.5710070325254419, 'colsample_bytree': 0.7853372847124238, 'min_child_weight': 1, 'scale_pos_weight': 1.3634751334064035}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:28:57,322] Trial 22 finished with value: 0.8279569892473119 and parameters: {'lambda': 1.1496110957516186, 'alpha': 8.021554606094481e-10, 'max_depth': 26, 'eta': 0.27024030090254775, 'subsample': 0.583672498074542, 'colsample_bytree': 0.7186887038385538, 'min_child_weight': 1, 'scale_pos_weight': 1.6913205995480067}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:29:01,269] Trial 23 finished with value: 0.8172043010752689 and parameters: {'lambda': 0.7709095764807475, 'alpha': 3.7756850591934885e-07, 'max_depth': 28, 'eta': 0.38823148645170785, 'subsample': 0.6032881980810327, 'colsample_bytree': 0.7987210907233994, 'min_child_weight': 1, 'scale_pos_weight': 3.039748896810483}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:29:04,983] Trial 24 finished with value: 0.8191489361702128 and parameters: {'lambda': 1.4257370141186256, 'alpha': 7.055192855936798e-08, 'max_depth': 20, 'eta': 0.4347191395398876, 'subsample': 0.5442667138774688, 'colsample_bytree': 0.8249663037342265, 'min_child_weight': 1, 'scale_pos_weight': 1.0222477102371401}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:29:10,164] Trial 25 finished with value: 0.8148148148148148 and parameters: {'lambda': 0.9452217228485098, 'alpha': 2.24397732174895e-10, 'max_depth': 22, 'eta': 0.24398709311535463, 'subsample': 0.6684713607178859, 'colsample_bytree': 0.9314759365977565, 'min_child_weight': 1, 'scale_pos_weight': 2.325067532279695}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:29:14,954] Trial 26 finished with value: 0.7938144329896907 and parameters: {'lambda': 1.9917546582506334, 'alpha': 6.160377359851485e-09, 'max_depth': 26, 'eta': 0.28965446886329804, 'subsample': 0.6311538773895958, 'colsample_bytree': 0.7207353984408239, 'min_child_weight': 1, 'scale_pos_weight': 3.7812253444561366}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:29:19,298] Trial 27 finished with value: 0.7835051546391752 and parameters: {'lambda': 1.1366337975549916, 'alpha': 1.0914604485436147e-05, 'max_depth': 24, 'eta': 0.34824041961542573, 'subsample': 0.5456475159562594, 'colsample_bytree': 0.6832800048780374, 'min_child_weight': 1, 'scale_pos_weight': 4.836446552726467}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:29:22,804] Trial 28 finished with value: 0.8324324324324325 and parameters: {'lambda': 0.855251603871561, 'alpha': 1.3337497162240074e-06, 'max_depth': 29, 'eta': 0.6227394808157303, 'subsample': 0.5762741507117938, 'colsample_bytree': 0.7779719097387302, 'min_child_weight': 1, 'scale_pos_weight': 1.518061770233089}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:29:25,984] Trial 29 finished with value: 0.8216216216216217 and parameters: {'lambda': 0.7102070448836364, 'alpha': 0.0021470861619024536, 'max_depth': 28, 'eta': 0.6291243227637513, 'subsample': 0.5598689407448093, 'colsample_bytree': 0.7646433829489565, 'min_child_weight': 1, 'scale_pos_weight': 1.9426771103927518}. Best is trial 5 with value: 0.8369565217391305.\n",
      "[I 2025-08-11 01:29:31,409] Trial 30 finished with value: 0.8444444444444444 and parameters: {'lambda': 1.0688023403845648, 'alpha': 5.08263185931462e-07, 'max_depth': 29, 'eta': 0.6165255640526531, 'subsample': 0.7194460878298488, 'colsample_bytree': 0.5968311691901453, 'min_child_weight': 1, 'scale_pos_weight': 2.5817979538997586}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:29:34,980] Trial 31 finished with value: 0.8085106382978723 and parameters: {'lambda': 1.0904332273220398, 'alpha': 7.97670929519334e-06, 'max_depth': 29, 'eta': 0.6295532608537299, 'subsample': 0.7241480968740043, 'colsample_bytree': 0.5557965361053605, 'min_child_weight': 1, 'scale_pos_weight': 2.815417812936457}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:29:38,406] Trial 32 finished with value: 0.8324324324324325 and parameters: {'lambda': 0.8595811850649977, 'alpha': 1.843370677349164e-07, 'max_depth': 30, 'eta': 0.52163226748668, 'subsample': 0.757544011959732, 'colsample_bytree': 0.632324731412193, 'min_child_weight': 1, 'scale_pos_weight': 1.5827843596075137}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:29:41,657] Trial 33 finished with value: 0.806282722513089 and parameters: {'lambda': 0.8807673172317488, 'alpha': 7.25663677672302e-07, 'max_depth': 29, 'eta': 0.6088168592483139, 'subsample': 0.7029096032107558, 'colsample_bytree': 0.7132818655286286, 'min_child_weight': 1, 'scale_pos_weight': 2.2044575255203562}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:29:45,757] Trial 34 finished with value: 0.8087431693989071 and parameters: {'lambda': 0.6786526753916373, 'alpha': 2.508691435504027e-08, 'max_depth': 30, 'eta': 0.493697416931865, 'subsample': 0.6770542455293601, 'colsample_bytree': 0.555379135210501, 'min_child_weight': 1, 'scale_pos_weight': 3.254185495424695}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:29:49,772] Trial 35 finished with value: 0.8020833333333334 and parameters: {'lambda': 1.7442173441023616, 'alpha': 4.37008350018715e-05, 'max_depth': 28, 'eta': 0.5806074556736395, 'subsample': 0.6276423863007823, 'colsample_bytree': 0.6449746075136422, 'min_child_weight': 1, 'scale_pos_weight': 7.079892905090896}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:29:53,681] Trial 36 finished with value: 0.7835051546391752 and parameters: {'lambda': 1.0567161704188959, 'alpha': 4.297293350890742e-06, 'max_depth': 29, 'eta': 0.4234536686431992, 'subsample': 0.5953591822381139, 'colsample_bytree': 0.757838309475984, 'min_child_weight': 2, 'scale_pos_weight': 2.712330235760203}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:29:56,981] Trial 37 finished with value: 0.8148148148148148 and parameters: {'lambda': 1.2557220868854722, 'alpha': 1.3657415128453644e-09, 'max_depth': 30, 'eta': 0.664381126860565, 'subsample': 0.6527462589471887, 'colsample_bytree': 0.9470263564331248, 'min_child_weight': 1, 'scale_pos_weight': 2.435012254614758}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:00,561] Trial 38 finished with value: 0.7958115183246073 and parameters: {'lambda': 1.8410334728116955, 'alpha': 1.2168975490855082e-06, 'max_depth': 27, 'eta': 0.5516687971813424, 'subsample': 0.5236133183869924, 'colsample_bytree': 0.8700348428150484, 'min_child_weight': 2, 'scale_pos_weight': 1.4400627537410293}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:03,907] Trial 39 finished with value: 0.7853403141361257 and parameters: {'lambda': 1.492197197345097, 'alpha': 1.216575661092903e-10, 'max_depth': 28, 'eta': 0.6402160788056893, 'subsample': 0.7542175513671904, 'colsample_bytree': 0.6061815879344562, 'min_child_weight': 1, 'scale_pos_weight': 2.060521285301793}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:07,553] Trial 40 finished with value: 0.8172043010752689 and parameters: {'lambda': 0.5356593575395792, 'alpha': 9.375033917055261e-08, 'max_depth': 30, 'eta': 0.5106856574857811, 'subsample': 0.5560214000575543, 'colsample_bytree': 0.7745873416356707, 'min_child_weight': 1, 'scale_pos_weight': 3.781191854034936}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:10,991] Trial 41 finished with value: 0.8235294117647058 and parameters: {'lambda': 0.845717273399528, 'alpha': 2.1552996933228016e-07, 'max_depth': 30, 'eta': 0.5285845374422556, 'subsample': 0.7625495017692042, 'colsample_bytree': 0.644350504888378, 'min_child_weight': 1, 'scale_pos_weight': 1.4581160684049774}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:14,277] Trial 42 finished with value: 0.8279569892473119 and parameters: {'lambda': 0.9017513491991077, 'alpha': 6.990909553003662e-07, 'max_depth': 29, 'eta': 0.5746989503011375, 'subsample': 0.728970749742332, 'colsample_bytree': 0.6771559141183203, 'min_child_weight': 1, 'scale_pos_weight': 1.63619420770101}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:18,001] Trial 43 finished with value: 0.8279569892473119 and parameters: {'lambda': 0.9963593139086379, 'alpha': 1.1845073198249605e-07, 'max_depth': 29, 'eta': 0.46790052278588556, 'subsample': 0.7640288227056728, 'colsample_bytree': 0.5825092574712425, 'min_child_weight': 1, 'scale_pos_weight': 2.5772376627485523}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:21,324] Trial 44 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.5957584644563174, 'alpha': 2.236942162142976e-09, 'max_depth': 30, 'eta': 0.6068282859163129, 'subsample': 0.7994967295250581, 'colsample_bytree': 0.6238767445342689, 'min_child_weight': 1, 'scale_pos_weight': 2.122600438985076}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:25,055] Trial 45 finished with value: 0.8324324324324325 and parameters: {'lambda': 0.7074849980543219, 'alpha': 6.879589618462836e-05, 'max_depth': 28, 'eta': 0.4285959242168807, 'subsample': 0.7161268600501309, 'colsample_bytree': 0.7332760560235719, 'min_child_weight': 1, 'scale_pos_weight': 1.3414595313064148}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:28,444] Trial 46 finished with value: 0.8128342245989305 and parameters: {'lambda': 0.8209414085782121, 'alpha': 2.488492341131704e-06, 'max_depth': 27, 'eta': 0.5552133005135255, 'subsample': 0.7468215870258778, 'colsample_bytree': 0.5713451941634664, 'min_child_weight': 1, 'scale_pos_weight': 2.0137334813047136}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:32,086] Trial 47 finished with value: 0.8415300546448088 and parameters: {'lambda': 1.64491286143264, 'alpha': 2.928766888285211e-08, 'max_depth': 30, 'eta': 0.46390836854286094, 'subsample': 0.7720571265373345, 'colsample_bytree': 0.6582940037303447, 'min_child_weight': 1, 'scale_pos_weight': 1.3151747126451965}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:35,850] Trial 48 finished with value: 0.8148148148148148 and parameters: {'lambda': 1.6517463313274616, 'alpha': 3.762775486853734e-08, 'max_depth': 29, 'eta': 0.4621241530964344, 'subsample': 0.7763303482453674, 'colsample_bytree': 0.7011858868473921, 'min_child_weight': 1, 'scale_pos_weight': 2.4233917989403984}. Best is trial 30 with value: 0.8444444444444444.\n",
      "[I 2025-08-11 01:30:40,039] Trial 49 finished with value: 0.8351648351648352 and parameters: {'lambda': 1.825433313294301, 'alpha': 1.2884409897425084e-08, 'max_depth': 27, 'eta': 0.3655524573130469, 'subsample': 0.7070120029437204, 'colsample_bytree': 0.8167350914430924, 'min_child_weight': 1, 'scale_pos_weight': 1.113205703405364}. Best is trial 30 with value: 0.8444444444444444.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lambda': 1.0688023403845648, 'alpha': 5.08263185931462e-07, 'max_depth': 29, 'eta': 0.6165255640526531, 'subsample': 0.7194460878298488, 'colsample_bytree': 0.5968311691901453, 'min_child_weight': 1, 'scale_pos_weight': 2.5817979538997586}\n",
      "Best F1 Score: 0.8444444444444444\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"tree_method\": \"hist\",  \n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 0.5, 2, log=False),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-11, 1, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 20, 30),\n",
    "        \"eta\": trial.suggest_float(\"eta\", 0.2, 0.7, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 0.8),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 2),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1, 8)  # Important for imbalance\n",
    "    }\n",
    "    #Best hyperparameters: {'lambda': 0.9718397047896502, 'alpha': 9.435569939830177e-09, 'max_depth': 15, 'eta': 0.22073806618552336, 'subsample': 0.5981116119161971, 'colsample_bytree': 0.5428281820554541, 'min_child_weight': 1, 'scale_pos_weight': 4.020635467730019}\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_resampled_SMOTE, label=y_train_resampled_SMOTE)\n",
    "    dvalid = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dvalid, \"validation\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "    preds = model.predict(dvalid)\n",
    "    preds_binary = (preds > 0.5).astype(int)\n",
    "    f1 = f1_score(y_test, preds_binary)\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best F1 Score:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682712d",
   "metadata": {},
   "source": [
    "trying optuna with random forrest best was 0.85 f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b945938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 01:48:04,797] A new study created in memory with name: no-name-5ac9c992-0396-41b2-88b7-10ed7f4c03c9\n",
      "[I 2025-08-11 01:53:59,078] Trial 0 finished with value: 0.8409090909090909 and parameters: {'max_depth': 46, 'n_estimators': 60}. Best is trial 0 with value: 0.8409090909090909.\n",
      "[I 2025-08-11 01:58:10,886] Trial 1 finished with value: 0.8275862068965517 and parameters: {'max_depth': 41, 'n_estimators': 42}. Best is trial 0 with value: 0.8409090909090909.\n",
      "[I 2025-08-11 02:04:15,374] Trial 2 finished with value: 0.8409090909090909 and parameters: {'max_depth': 48, 'n_estimators': 61}. Best is trial 0 with value: 0.8409090909090909.\n",
      "[I 2025-08-11 02:09:20,473] Trial 3 finished with value: 0.8409090909090909 and parameters: {'max_depth': 43, 'n_estimators': 51}. Best is trial 0 with value: 0.8409090909090909.\n",
      "[I 2025-08-11 02:14:46,152] Trial 4 finished with value: 0.8275862068965517 and parameters: {'max_depth': 41, 'n_estimators': 54}. Best is trial 0 with value: 0.8409090909090909.\n",
      "[I 2025-08-11 02:21:15,989] Trial 5 finished with value: 0.8342857142857143 and parameters: {'max_depth': 44, 'n_estimators': 65}. Best is trial 0 with value: 0.8409090909090909.\n",
      "[I 2025-08-11 02:27:33,645] Trial 6 finished with value: 0.8409090909090909 and parameters: {'max_depth': 47, 'n_estimators': 62}. Best is trial 0 with value: 0.8409090909090909.\n",
      "[I 2025-08-11 02:34:25,648] Trial 7 finished with value: 0.8342857142857143 and parameters: {'max_depth': 45, 'n_estimators': 69}. Best is trial 0 with value: 0.8409090909090909.\n",
      "[I 2025-08-11 02:38:08,465] Trial 8 finished with value: 0.847457627118644 and parameters: {'max_depth': 50, 'n_estimators': 43}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 02:41:52,853] Trial 9 finished with value: 0.847457627118644 and parameters: {'max_depth': 46, 'n_estimators': 45}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 02:45:48,701] Trial 10 finished with value: 0.847457627118644 and parameters: {'max_depth': 49, 'n_estimators': 47}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 02:49:15,195] Trial 11 finished with value: 0.8409090909090909 and parameters: {'max_depth': 50, 'n_estimators': 40}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 02:53:12,453] Trial 12 finished with value: 0.847457627118644 and parameters: {'max_depth': 48, 'n_estimators': 47}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 02:57:01,196] Trial 13 finished with value: 0.847457627118644 and parameters: {'max_depth': 50, 'n_estimators': 45}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 03:01:20,868] Trial 14 finished with value: 0.8409090909090909 and parameters: {'max_depth': 43, 'n_estimators': 51}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 03:05:09,370] Trial 15 finished with value: 0.8522727272727273 and parameters: {'max_depth': 46, 'n_estimators': 44}. Best is trial 15 with value: 0.8522727272727273.\n",
      "[I 2025-08-11 03:08:27,949] Trial 16 finished with value: 0.8409090909090909 and parameters: {'max_depth': 48, 'n_estimators': 40}. Best is trial 15 with value: 0.8522727272727273.\n",
      "[I 2025-08-11 03:12:44,768] Trial 17 finished with value: 0.8409090909090909 and parameters: {'max_depth': 46, 'n_estimators': 51}. Best is trial 15 with value: 0.8522727272727273.\n",
      "[I 2025-08-11 03:16:18,875] Trial 18 finished with value: 0.8409090909090909 and parameters: {'max_depth': 40, 'n_estimators': 43}. Best is trial 15 with value: 0.8522727272727273.\n",
      "[I 2025-08-11 03:20:52,998] Trial 19 finished with value: 0.8409090909090909 and parameters: {'max_depth': 49, 'n_estimators': 56}. Best is trial 15 with value: 0.8522727272727273.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth',40,50)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 40, 70)\n",
    "    clf = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=42)\n",
    "    clf.fit(X_train_resampled_SMOTE,y_train_resampled_SMOTE)\n",
    "    y_pred_rf = clf.predict(X_test_scaled)\n",
    "    return f1_score(y_test, y_pred_rf)\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c26e09",
   "metadata": {},
   "source": [
    "same model but using best parama. high precision but low recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "354bcd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = RandomForestClassifier(max_depth=46, n_estimators=45, random_state=42)\n",
    "clf.fit(X_train_resampled_SMOTE,y_train_resampled_SMOTE)\n",
    "y_pred_rf = clf.predict(X_test_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523afec8",
   "metadata": {},
   "source": [
    "random forrest with smote sampled 0.85 f1 score and 0.91 precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "06f5b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847457627118644\n",
      "0.9146341463414634\n",
      "0.7894736842105263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.91      0.79      0.85        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.96      0.89      0.92     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "[[56644     7]\n",
      " [   20    75]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score , f1_score,precision_score,classification_report,confusion_matrix\n",
    "print(f1_score(y_test, y_pred_rf)) \n",
    "print(precision_score(y_test, y_pred_rf)) \n",
    "print(recall_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f71cbd",
   "metadata": {},
   "source": [
    "RF with heighest precision but low precision , only scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afff7713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8242424242424242\n",
      "0.9714285714285714\n",
      "0.7157894736842105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.97      0.72      0.82        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.99      0.86      0.91     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "[[56649     2]\n",
      " [   27    68]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score , f1_score,precision_score,classification_report,confusion_matrix\n",
    "clf = RandomForestClassifier(max_depth=47, n_estimators=45, random_state=42)\n",
    "clf.fit(X_train_scalled,y_train)\n",
    "y_pred_rf = clf.predict(X_test_scaled)\n",
    "print(f1_score(y_test, y_pred_rf)) \n",
    "print(precision_score(y_test, y_pred_rf)) \n",
    "print(recall_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc5e7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using selected feat.\n",
    "#[3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 27]\n",
    "selected_indices_smote = [2, 3, 4,7,8,9,10,11,12,14,16,17,18,19,26]\n",
    "X_train_selected_smote = X_train_resampled_SMOTE[:, selected_indices_smote]\n",
    "X_test_selected = X_test_scaled[:, selected_indices_smote]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b4e4b",
   "metadata": {},
   "source": [
    "RF but with selected features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80dd17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdullahyehia/Desktop/NTI-Project/Credit-Card-Fraud_Detection/tf-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-08-11 15:11:35,882] A new study created in memory with name: no-name-4098378e-816f-46cd-856e-2f7c4f32c94f\n",
      "[I 2025-08-11 15:15:54,411] Trial 0 finished with value: 0.8087431693989071 and parameters: {'max_depth': 59, 'n_estimators': 68}. Best is trial 0 with value: 0.8087431693989071.\n",
      "[I 2025-08-11 15:18:48,792] Trial 1 finished with value: 0.7934782608695652 and parameters: {'max_depth': 59, 'n_estimators': 46}. Best is trial 0 with value: 0.8087431693989071.\n",
      "[I 2025-08-11 15:22:45,723] Trial 2 finished with value: 0.8131868131868132 and parameters: {'max_depth': 40, 'n_estimators': 64}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:26:14,904] Trial 3 finished with value: 0.7978142076502732 and parameters: {'max_depth': 50, 'n_estimators': 56}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:30:17,601] Trial 4 finished with value: 0.8 and parameters: {'max_depth': 41, 'n_estimators': 67}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:33:57,085] Trial 5 finished with value: 0.8021978021978022 and parameters: {'max_depth': 47, 'n_estimators': 60}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:36:43,913] Trial 6 finished with value: 0.7934782608695652 and parameters: {'max_depth': 51, 'n_estimators': 44}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:40:34,196] Trial 7 finished with value: 0.8043478260869565 and parameters: {'max_depth': 54, 'n_estimators': 69}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:43:45,298] Trial 8 finished with value: 0.8 and parameters: {'max_depth': 47, 'n_estimators': 65}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:45:37,176] Trial 9 finished with value: 0.7891891891891892 and parameters: {'max_depth': 42, 'n_estimators': 41}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:49:06,995] Trial 10 finished with value: 0.8043478260869565 and parameters: {'max_depth': 40, 'n_estimators': 75}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:52:54,023] Trial 11 finished with value: 0.8087431693989071 and parameters: {'max_depth': 60, 'n_estimators': 80}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:55:26,095] Trial 12 finished with value: 0.7978142076502732 and parameters: {'max_depth': 56, 'n_estimators': 54}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 15:58:52,653] Trial 13 finished with value: 0.8087431693989071 and parameters: {'max_depth': 44, 'n_estimators': 74}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:01:39,602] Trial 14 finished with value: 0.8021978021978022 and parameters: {'max_depth': 56, 'n_estimators': 60}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:04:02,881] Trial 15 finished with value: 0.7934782608695652 and parameters: {'max_depth': 45, 'n_estimators': 52}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:07:00,117] Trial 16 finished with value: 0.8131868131868132 and parameters: {'max_depth': 51, 'n_estimators': 64}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:09:59,558] Trial 17 finished with value: 0.8131868131868132 and parameters: {'max_depth': 51, 'n_estimators': 64}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:12:45,779] Trial 18 finished with value: 0.8021978021978022 and parameters: {'max_depth': 53, 'n_estimators': 60}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:16:01,848] Trial 19 finished with value: 0.8087431693989071 and parameters: {'max_depth': 47, 'n_estimators': 72}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:18:18,734] Trial 20 finished with value: 0.7934782608695652 and parameters: {'max_depth': 44, 'n_estimators': 49}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:21:23,038] Trial 21 finished with value: 0.8131868131868132 and parameters: {'max_depth': 52, 'n_estimators': 64}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:24:31,166] Trial 22 finished with value: 0.8043478260869565 and parameters: {'max_depth': 50, 'n_estimators': 63}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:27:08,349] Trial 23 finished with value: 0.7978142076502732 and parameters: {'max_depth': 49, 'n_estimators': 56}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:30:41,160] Trial 24 finished with value: 0.8043478260869565 and parameters: {'max_depth': 55, 'n_estimators': 71}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:33:19,295] Trial 25 finished with value: 0.8043478260869565 and parameters: {'max_depth': 49, 'n_estimators': 59}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:36:10,134] Trial 26 finished with value: 0.8131868131868132 and parameters: {'max_depth': 52, 'n_estimators': 64}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:39:12,196] Trial 27 finished with value: 0.8 and parameters: {'max_depth': 48, 'n_estimators': 77}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:41:39,609] Trial 28 finished with value: 0.8087431693989071 and parameters: {'max_depth': 57, 'n_estimators': 62}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:44:18,463] Trial 29 finished with value: 0.8043478260869565 and parameters: {'max_depth': 53, 'n_estimators': 67}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:47:04,662] Trial 30 finished with value: 0.8087431693989071 and parameters: {'max_depth': 45, 'n_estimators': 70}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:49:38,471] Trial 31 finished with value: 0.8 and parameters: {'max_depth': 52, 'n_estimators': 65}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:52:18,530] Trial 32 finished with value: 0.8087431693989071 and parameters: {'max_depth': 52, 'n_estimators': 68}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:54:33,293] Trial 33 finished with value: 0.7934782608695652 and parameters: {'max_depth': 50, 'n_estimators': 57}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:57:03,297] Trial 34 finished with value: 0.8087431693989071 and parameters: {'max_depth': 58, 'n_estimators': 62}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 16:59:54,823] Trial 35 finished with value: 0.8043478260869565 and parameters: {'max_depth': 51, 'n_estimators': 67}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 17:02:34,976] Trial 36 finished with value: 0.8021978021978022 and parameters: {'max_depth': 54, 'n_estimators': 58}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 17:04:49,569] Trial 37 finished with value: 0.7934782608695652 and parameters: {'max_depth': 48, 'n_estimators': 53}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 17:07:26,315] Trial 38 finished with value: 0.8087431693989071 and parameters: {'max_depth': 51, 'n_estimators': 62}. Best is trial 2 with value: 0.8131868131868132.\n",
      "[I 2025-08-11 17:10:41,602] Trial 39 finished with value: 0.8 and parameters: {'max_depth': 54, 'n_estimators': 65}. Best is trial 2 with value: 0.8131868131868132.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna\n",
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int('max_depth',40,60)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 40, 80)\n",
    "    clf = RandomForestClassifier(max_depth=max_depth, n_estimators=n_estimators, random_state=42)\n",
    "    clf.fit(X_train_selected_smote,y_train_resampled_SMOTE)\n",
    "    y_pred_rf = clf.predict(X_test_selected)\n",
    "    return f1_score(y_test, y_pred_rf)\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6fe0c",
   "metadata": {},
   "source": [
    "using XGBoost with optuna to maxmize recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "133416b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 00:59:09,715] A new study created in memory with name: no-name-1140d6ea-ccc7-4e9a-9500-55bd9a23a453\n",
      "[I 2025-08-12 00:59:20,208] Trial 0 finished with value: 0.8 and parameters: {'lambda': 0.010071999419732063, 'alpha': 0.0019361994401202482, 'max_depth': 13, 'eta': 0.17316738577196603, 'subsample': 0.7890596934449943, 'colsample_bytree': 0.7757415308174858, 'min_child_weight': 2}. Best is trial 0 with value: 0.8.\n",
      "[I 2025-08-12 00:59:29,774] Trial 1 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.2538047379165173, 'alpha': 1.1744911465072014, 'max_depth': 14, 'eta': 0.11380204072807187, 'subsample': 0.704917755407737, 'colsample_bytree': 0.8303000834024498, 'min_child_weight': 4}. Best is trial 1 with value: 0.8105263157894737.\n",
      "[I 2025-08-12 00:59:42,151] Trial 2 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.025816578984897524, 'alpha': 0.0037735486627134807, 'max_depth': 12, 'eta': 0.12125812818345844, 'subsample': 0.7495704933747864, 'colsample_bytree': 0.7452380701243719, 'min_child_weight': 3}. Best is trial 1 with value: 0.8105263157894737.\n",
      "[I 2025-08-12 00:59:48,600] Trial 3 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.4276770722152435, 'alpha': 0.0021561560395512306, 'max_depth': 6, 'eta': 0.10586631285314568, 'subsample': 0.7891406357910207, 'colsample_bytree': 0.6443034654562492, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:00:04,652] Trial 4 finished with value: 0.8 and parameters: {'lambda': 0.005111298117397425, 'alpha': 0.11463562358014724, 'max_depth': 10, 'eta': 0.11509010214319133, 'subsample': 0.6713041428421294, 'colsample_bytree': 0.7624301494800481, 'min_child_weight': 2}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:00:19,438] Trial 5 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.1111357033230204, 'alpha': 0.007249027918597926, 'max_depth': 11, 'eta': 0.0821367036000222, 'subsample': 0.5972340807768977, 'colsample_bytree': 0.5076714580267123, 'min_child_weight': 2}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:00:32,860] Trial 6 finished with value: 0.8 and parameters: {'lambda': 0.1463420991992076, 'alpha': 0.00990486627037036, 'max_depth': 13, 'eta': 0.09714057466002463, 'subsample': 0.5962989893482892, 'colsample_bytree': 0.5888212806018979, 'min_child_weight': 1}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:00:44,815] Trial 7 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.00435772564220196, 'alpha': 0.0011320844212635121, 'max_depth': 7, 'eta': 0.14046341314145125, 'subsample': 0.6476068921618601, 'colsample_bytree': 0.9186990033176883, 'min_child_weight': 1}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:00:58,552] Trial 8 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.025612519690427465, 'alpha': 0.0010170728314805434, 'max_depth': 6, 'eta': 0.08854096084237617, 'subsample': 0.8726696551192932, 'colsample_bytree': 0.9311478782193965, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:01:26,521] Trial 9 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.9313657589163252, 'alpha': 0.2364838008089052, 'max_depth': 15, 'eta': 0.057460001774217714, 'subsample': 0.6578689642113532, 'colsample_bytree': 0.730417321953923, 'min_child_weight': 5}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:01:31,474] Trial 10 finished with value: 0.8105263157894737 and parameters: {'lambda': 1.6473823686540165, 'alpha': 0.03076981947021322, 'max_depth': 9, 'eta': 0.27657634880094906, 'subsample': 0.8614601835687579, 'colsample_bytree': 0.63491319943178, 'min_child_weight': 5}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:01:36,162] Trial 11 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.04217808598849867, 'alpha': 0.001146412305790438, 'max_depth': 5, 'eta': 0.069000667255079, 'subsample': 0.870858869704186, 'colsample_bytree': 0.9882384875432659, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:01:41,018] Trial 12 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.0011268110232054405, 'alpha': 0.017922724180822053, 'max_depth': 5, 'eta': 0.17732562447831418, 'subsample': 0.8087399105325633, 'colsample_bytree': 0.6509074303982081, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:01:50,046] Trial 13 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.42310937920810204, 'alpha': 0.004020680191944541, 'max_depth': 7, 'eta': 0.05132141663491042, 'subsample': 0.5020066333553377, 'colsample_bytree': 0.8612562677052193, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:01:59,232] Trial 14 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.07717755004256456, 'alpha': 0.08589960595485256, 'max_depth': 7, 'eta': 0.08114057735544013, 'subsample': 0.8262615603465778, 'colsample_bytree': 0.9805548552446659, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:02:11,282] Trial 15 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.01912914933776121, 'alpha': 0.0035098697754994677, 'max_depth': 8, 'eta': 0.16336184727945333, 'subsample': 0.8953638585568446, 'colsample_bytree': 0.6840041176540774, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:02:17,946] Trial 16 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.29836961353110286, 'alpha': 0.010791999513385955, 'max_depth': 6, 'eta': 0.23774393802136212, 'subsample': 0.7407254387219052, 'colsample_bytree': 0.5587084323870549, 'min_child_weight': 5}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:02:27,676] Trial 17 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.6797108647960632, 'alpha': 1.154434651356059, 'max_depth': 9, 'eta': 0.08541755384857777, 'subsample': 0.7650647697807188, 'colsample_bytree': 0.8867173987042847, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:02:40,700] Trial 18 finished with value: 0.8 and parameters: {'lambda': 0.06101582788451122, 'alpha': 0.0023984821264483583, 'max_depth': 6, 'eta': 0.06911205444642503, 'subsample': 0.8395983257934396, 'colsample_bytree': 0.7999716888590305, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:02:53,547] Trial 19 finished with value: 0.8 and parameters: {'lambda': 0.0010331925781893784, 'alpha': 0.001058573008054452, 'max_depth': 8, 'eta': 0.09620968015394189, 'subsample': 0.8945510724064618, 'colsample_bytree': 0.6977120060480956, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:03:01,897] Trial 20 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.015484162296919714, 'alpha': 0.38221084590453713, 'max_depth': 5, 'eta': 0.1366516469611374, 'subsample': 0.8004472542776332, 'colsample_bytree': 0.9362659758152312, 'min_child_weight': 2}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:03:15,910] Trial 21 finished with value: 0.8 and parameters: {'lambda': 0.03909848578653751, 'alpha': 0.0010393297360474464, 'max_depth': 5, 'eta': 0.06771532969791859, 'subsample': 0.8589069564858535, 'colsample_bytree': 0.9993156945754432, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:03:24,732] Trial 22 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.03907316728961904, 'alpha': 0.0019023119841056083, 'max_depth': 6, 'eta': 0.07151710947784011, 'subsample': 0.8650200344091069, 'colsample_bytree': 0.9606838601587249, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:03:35,043] Trial 23 finished with value: 0.8 and parameters: {'lambda': 0.00976584790708774, 'alpha': 0.00503411645966288, 'max_depth': 5, 'eta': 0.09838328898926776, 'subsample': 0.8957326891167547, 'colsample_bytree': 0.8944860588350867, 'min_child_weight': 5}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:03:53,572] Trial 24 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.17360583594008983, 'alpha': 0.0020122761900873034, 'max_depth': 8, 'eta': 0.06328386315122214, 'subsample': 0.7790168926216693, 'colsample_bytree': 0.836005454627234, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:04:15,638] Trial 25 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.09072401333629095, 'alpha': 0.014648420706819083, 'max_depth': 6, 'eta': 0.0787313400046499, 'subsample': 0.8315807883572313, 'colsample_bytree': 0.9546023456245306, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:04:24,714] Trial 26 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.0028544188318081532, 'alpha': 0.0016449026903932707, 'max_depth': 7, 'eta': 0.05036265686019845, 'subsample': 0.86305129789488, 'colsample_bytree': 0.6034042320583608, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:04:40,900] Trial 27 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.03369481870952608, 'alpha': 0.03508072660943718, 'max_depth': 9, 'eta': 0.0984699464442162, 'subsample': 0.7215738345569412, 'colsample_bytree': 0.9027010416680561, 'min_child_weight': 5}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:04:47,906] Trial 28 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.011450617910188147, 'alpha': 0.006245884177656218, 'max_depth': 6, 'eta': 0.08926580802128373, 'subsample': 0.8198558628077796, 'colsample_bytree': 0.544331681582796, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:04:59,948] Trial 29 finished with value: 0.8 and parameters: {'lambda': 0.06052473621673761, 'alpha': 0.0027807796003533093, 'max_depth': 5, 'eta': 0.10755629820739605, 'subsample': 0.7838186429996198, 'colsample_bytree': 0.9984761480111817, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:05:16,669] Trial 30 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.005777474700816293, 'alpha': 0.0016187622264133739, 'max_depth': 10, 'eta': 0.06228892444297766, 'subsample': 0.8460711212119589, 'colsample_bytree': 0.7792114235751102, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:05:32,396] Trial 31 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.5273731965929457, 'alpha': 0.003957115891966114, 'max_depth': 6, 'eta': 0.05081171031505371, 'subsample': 0.5795364542602925, 'colsample_bytree': 0.8673358862478177, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:05:46,249] Trial 32 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.3358616160213602, 'alpha': 0.0010004580881698834, 'max_depth': 7, 'eta': 0.058686011194834437, 'subsample': 0.5262135893367498, 'colsample_bytree': 0.8512154851507758, 'min_child_weight': 2}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:06:00,286] Trial 33 finished with value: 0.8 and parameters: {'lambda': 0.21586738284212048, 'alpha': 0.0028839502367403666, 'max_depth': 7, 'eta': 0.07530120988979332, 'subsample': 0.5043852612556787, 'colsample_bytree': 0.932974148734933, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:06:11,311] Trial 34 finished with value: 0.8210526315789474 and parameters: {'lambda': 1.7200146485894166, 'alpha': 0.005099379483716621, 'max_depth': 8, 'eta': 0.05464325693466943, 'subsample': 0.6873564259105693, 'colsample_bytree': 0.8210866689568249, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:06:19,881] Trial 35 finished with value: 0.8210526315789474 and parameters: {'lambda': 1.1184412524178255, 'alpha': 0.0015512253419741806, 'max_depth': 5, 'eta': 0.13596668661112032, 'subsample': 0.5498994719206898, 'colsample_bytree': 0.9615764436675343, 'min_child_weight': 2}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:06:31,545] Trial 36 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.3721664826414905, 'alpha': 0.0071481356532243166, 'max_depth': 6, 'eta': 0.109334593583823, 'subsample': 0.6392213264932192, 'colsample_bytree': 0.7299107475412483, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:06:39,974] Trial 37 finished with value: 0.8 and parameters: {'lambda': 0.12634961585756835, 'alpha': 0.003488093950180366, 'max_depth': 12, 'eta': 0.12219601761281018, 'subsample': 0.8796919305327412, 'colsample_bytree': 0.9195269748964178, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:06:54,395] Trial 38 finished with value: 0.8 and parameters: {'lambda': 0.025400787207345607, 'alpha': 0.0014654066438033763, 'max_depth': 7, 'eta': 0.06519119152190495, 'subsample': 0.7207478603038003, 'colsample_bytree': 0.8847787410811606, 'min_child_weight': 2}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:07:10,540] Trial 39 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.20569467420409124, 'alpha': 0.021793202250112633, 'max_depth': 11, 'eta': 0.0903941214983528, 'subsample': 0.6260933102982477, 'colsample_bytree': 0.7985213579191736, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:07:13,360] Trial 40 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.4735026151950053, 'alpha': 0.07133940667400687, 'max_depth': 5, 'eta': 0.05514324319329812, 'subsample': 0.7632087740332288, 'colsample_bytree': 0.8566711393707729, 'min_child_weight': 1}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:07:22,043] Trial 41 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.04491290351722859, 'alpha': 0.0024446472143027738, 'max_depth': 6, 'eta': 0.07256858774367367, 'subsample': 0.8694704895897652, 'colsample_bytree': 0.9639827097876871, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:07:28,249] Trial 42 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.025198072333362145, 'alpha': 0.0020568945586602774, 'max_depth': 6, 'eta': 0.0739549759686171, 'subsample': 0.7996594986967802, 'colsample_bytree': 0.9365941386909624, 'min_child_weight': 5}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:07:36,615] Trial 43 finished with value: 0.8210526315789474 and parameters: {'lambda': 0.05594037363756284, 'alpha': 0.009441480292118722, 'max_depth': 7, 'eta': 0.0595242590882114, 'subsample': 0.8485306884280502, 'colsample_bytree': 0.9664111803279848, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:07:46,343] Trial 44 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.09789104242132386, 'alpha': 0.0013283693486092416, 'max_depth': 15, 'eta': 0.08270379624962597, 'subsample': 0.87753124730794, 'colsample_bytree': 0.9809715290106591, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:07:58,281] Trial 45 finished with value: 0.8 and parameters: {'lambda': 0.018772860574651634, 'alpha': 0.004687522572249267, 'max_depth': 8, 'eta': 0.0698532771670412, 'subsample': 0.8125921440443427, 'colsample_bytree': 0.9091826887310919, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:08:05,159] Trial 46 finished with value: 0.7894736842105263 and parameters: {'lambda': 0.033525850206258964, 'alpha': 0.0020577668445983795, 'max_depth': 6, 'eta': 0.1532031406642077, 'subsample': 0.8313973050114626, 'colsample_bytree': 0.6700952703753043, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:08:12,229] Trial 47 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.8191674049134992, 'alpha': 0.0029014987551932345, 'max_depth': 14, 'eta': 0.11142588899282199, 'subsample': 0.7437813192149828, 'colsample_bytree': 0.6125366018905105, 'min_child_weight': 3}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:08:18,752] Trial 48 finished with value: 0.8105263157894737 and parameters: {'lambda': 0.011535588396117279, 'alpha': 0.28038380592908974, 'max_depth': 5, 'eta': 0.18487902286439656, 'subsample': 0.6732344493149849, 'colsample_bytree': 0.7141298012355488, 'min_child_weight': 4}. Best is trial 3 with value: 0.8210526315789474.\n",
      "[I 2025-08-12 01:08:32,527] Trial 49 finished with value: 0.8 and parameters: {'lambda': 0.1386829034787501, 'alpha': 0.0012760271563049923, 'max_depth': 9, 'eta': 0.08837446615096835, 'subsample': 0.8816721432596748, 'colsample_bytree': 0.9818880978712734, 'min_child_weight': 5}. Best is trial 3 with value: 0.8210526315789474.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lambda': 0.4276770722152435, 'alpha': 0.0021561560395512306, 'max_depth': 6, 'eta': 0.10586631285314568, 'subsample': 0.7891406357910207, 'colsample_bytree': 0.6443034654562492, 'min_child_weight': 4}\n",
      "Best recall Score: 0.8210526315789474\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_score, f1_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "      \"objective\": \"binary:logistic\",\n",
    "      \"eval_metric\": \"aucpr\",\n",
    "      \"tree_method\": \"hist\",\n",
    "      \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 2, log=True),\n",
    "      \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 2, log=True),\n",
    "      \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15),\n",
    "      \"eta\": trial.suggest_float(\"eta\", 0.05, 0.3, log=True),\n",
    "      \"subsample\": trial.suggest_float(\"subsample\", 0.5, 0.9),\n",
    "      \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "      \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n",
    "      \"scale_pos_weight\": 1\n",
    "    }\n",
    "    #Best hyperparameters: {'lambda': 0.9718397047896502, 'alpha': 9.435569939830177e-09, 'max_depth': 15, 'eta': 0.22073806618552336, 'subsample': 0.5981116119161971, 'colsample_bytree': 0.5428281820554541, 'min_child_weight': 1, 'scale_pos_weight': 4.020635467730019}\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_resampled_SMOTE, label=y_train_resampled_SMOTE)\n",
    "    dvalid = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dvalid, \"validation\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    preds = model.predict(dvalid)\n",
    "    preds_binary = (preds > 0.5).astype(int)\n",
    "\n",
    "    # We'll optimize for recall score\n",
    "    recall = recall_score(y_test, preds_binary)\n",
    "    return recall\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best recall Score:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e01de",
   "metadata": {},
   "source": [
    "up unntil here reviewd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d271132",
   "metadata": {},
   "source": [
    "smote resampled with xgboost , best parameters from the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2896ce88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with value: 0.8526315789473684 and parameters: {'lambda': 1.2849123752082519, 'alpha': 0.0015785509725834937, 'max_depth': 5, 'eta': 0.054439982049962664, 'subsample': 0.8814321331898017, 'colsample_bytree': 0.545755020238372, 'min_child_weight': 2}. Best is trial 31 with value: 0.8526315789473684.\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_score, f1_score , accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"aucpr\",\n",
    "        \"tree_method\": \"hist\",  # \"gpu_hist\" if GPU available\n",
    "        \"lambda\": 0.4276770722152435,\n",
    "        \"alpha\": 0.0021561560395512306,\n",
    "        \"max_depth\": 6,\n",
    "        \"eta\": 0.10586631285314568,\n",
    "        \"subsample\": 0.7891406357910207,\n",
    "        \"colsample_bytree\": 0.6443034654562492,\n",
    "        \"min_child_weight\": 4,\n",
    "        \"scale_pos_weight\": 1   # Important for imbalance\n",
    "    }\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_resampled_SMOTE, label=y_train_resampled_SMOTE)\n",
    "dvalid = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "\n",
    "modelXG = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dvalid, \"validation\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False)\n",
    "\n",
    "preds = modelXG.predict(dvalid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4aa8a",
   "metadata": {},
   "source": [
    "extremley low precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f343de05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5909090909090909\n",
      "0.46153846153846156\n",
      "0.8210526315789474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.46      0.82      0.59        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.73      0.91      0.79     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "[[56560    91]\n",
      " [   17    78]]\n",
      "0.998096782152046\n"
     ]
    }
   ],
   "source": [
    "preds_binary = (preds > 0.5).astype(int)\n",
    "\n",
    "print(f1_score(y_test, preds_binary)) \n",
    "print(precision_score(y_test, preds_binary)) \n",
    "print(recall_score(y_test, preds_binary))\n",
    "print(classification_report(y_test, preds_binary))\n",
    "print(confusion_matrix(y_test, preds_binary))\n",
    "print(accuracy_score(y_test, preds_binary))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322163dc",
   "metadata": {},
   "source": [
    "best RF with acceptable overall scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac84dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.847457627118644\n",
      "0.9146341463414634\n",
      "0.7894736842105263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.91      0.79      0.85        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.96      0.89      0.92     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "[[56644     7]\n",
      " [   20    75]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score , f1_score,precision_score,classification_report,confusion_matrix\n",
    "clfFinal = RandomForestClassifier(max_depth=46, n_estimators=45, random_state=42)\n",
    "clfFinal.fit(X_train_resampled_SMOTE,y_train_resampled_SMOTE)\n",
    "y_pred_rf = clfFinal.predict(X_test_scaled)\n",
    "from sklearn.metrics import recall_score , f1_score,precision_score,classification_report,confusion_matrix\n",
    "print(f1_score(y_test, y_pred_rf)) \n",
    "print(precision_score(y_test, y_pred_rf)) \n",
    "print(recall_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181231ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud_model_RF.pkl']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clfFinal, \"fraud_model_RF.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441a0c3",
   "metadata": {},
   "source": [
    "Tying random over sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b346a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    226602\n",
      "1    226602\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "X_train_resampled_ROS, y_train_resampled_ROS = oversampler.fit_resample(X_train_scalled, y_train)\n",
    "print(y_train_resampled_ROS.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701c8665",
   "metadata": {},
   "source": [
    "optuna with xgoost , random over sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66e87c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 22:47:36,672] A new study created in memory with name: no-name-77e318ed-68de-433a-8709-40efadc867e3\n",
      "[I 2025-08-11 22:47:49,565] Trial 0 finished with value: 0.8043478260869565 and parameters: {'lambda': 0.17728660129342444, 'alpha': 0.022102639782714935, 'max_depth': 6, 'eta': 0.15100409817837104, 'subsample': 0.7164917947690701, 'colsample_bytree': 0.9423342579919729, 'min_child_weight': 4}. Best is trial 0 with value: 0.8043478260869565.\n",
      "[I 2025-08-11 22:47:57,955] Trial 1 finished with value: 0.8202247191011236 and parameters: {'lambda': 0.495551382694251, 'alpha': 0.008272466473308386, 'max_depth': 13, 'eta': 0.2517026049660995, 'subsample': 0.712165703443933, 'colsample_bytree': 0.9841008904254129, 'min_child_weight': 2}. Best is trial 1 with value: 0.8202247191011236.\n",
      "[I 2025-08-11 22:48:10,318] Trial 2 finished with value: 0.8176795580110497 and parameters: {'lambda': 1.4142582210117474, 'alpha': 0.19484721662705165, 'max_depth': 10, 'eta': 0.1575929708308898, 'subsample': 0.5596442720596644, 'colsample_bytree': 0.8127019377325485, 'min_child_weight': 2}. Best is trial 1 with value: 0.8202247191011236.\n",
      "[I 2025-08-11 22:48:19,189] Trial 3 finished with value: 0.7789473684210526 and parameters: {'lambda': 0.026202471959388737, 'alpha': 0.015052777071113953, 'max_depth': 15, 'eta': 0.053084872403971015, 'subsample': 0.7614057913620738, 'colsample_bytree': 0.7037653242923192, 'min_child_weight': 5}. Best is trial 1 with value: 0.8202247191011236.\n",
      "[I 2025-08-11 22:48:26,685] Trial 4 finished with value: 0.8156424581005587 and parameters: {'lambda': 0.003948936353272588, 'alpha': 1.8350693911996032, 'max_depth': 8, 'eta': 0.266432798201196, 'subsample': 0.8892137630439181, 'colsample_bytree': 0.6592802130371123, 'min_child_weight': 1}. Best is trial 1 with value: 0.8202247191011236.\n",
      "[I 2025-08-11 22:48:59,762] Trial 5 finished with value: 0.819672131147541 and parameters: {'lambda': 0.20522312447761015, 'alpha': 0.008267049698471696, 'max_depth': 5, 'eta': 0.05901661150713083, 'subsample': 0.7738310715284965, 'colsample_bytree': 0.7172626577609789, 'min_child_weight': 4}. Best is trial 1 with value: 0.8202247191011236.\n",
      "[I 2025-08-11 22:49:14,234] Trial 6 finished with value: 0.8216216216216217 and parameters: {'lambda': 0.0010901162326282777, 'alpha': 0.13629364528348975, 'max_depth': 5, 'eta': 0.14277836879020098, 'subsample': 0.7463944645185736, 'colsample_bytree': 0.6937264276396178, 'min_child_weight': 4}. Best is trial 6 with value: 0.8216216216216217.\n",
      "[I 2025-08-11 22:49:24,825] Trial 7 finished with value: 0.8202247191011236 and parameters: {'lambda': 1.0887141721605282, 'alpha': 0.002442616960318288, 'max_depth': 9, 'eta': 0.21601065558303165, 'subsample': 0.5936241616275139, 'colsample_bytree': 0.9945812354655221, 'min_child_weight': 2}. Best is trial 6 with value: 0.8216216216216217.\n",
      "[I 2025-08-11 22:49:36,475] Trial 8 finished with value: 0.847457627118644 and parameters: {'lambda': 1.9119812446110687, 'alpha': 0.0025955153490212764, 'max_depth': 6, 'eta': 0.14353507961401027, 'subsample': 0.7024072922443778, 'colsample_bytree': 0.7650635133316329, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:49:45,046] Trial 9 finished with value: 0.8021390374331551 and parameters: {'lambda': 0.00569961097309627, 'alpha': 0.02498640445687209, 'max_depth': 7, 'eta': 0.17610758982709135, 'subsample': 0.5716501868464808, 'colsample_bytree': 0.9636801162669502, 'min_child_weight': 4}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:50:13,550] Trial 10 finished with value: 0.8295454545454546 and parameters: {'lambda': 0.04224392623173515, 'alpha': 0.0019267266324820213, 'max_depth': 12, 'eta': 0.09664847238703622, 'subsample': 0.6375114700873703, 'colsample_bytree': 0.5219906103063974, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:50:34,752] Trial 11 finished with value: 0.8228571428571428 and parameters: {'lambda': 0.041192530507285496, 'alpha': 0.0010501976265194278, 'max_depth': 12, 'eta': 0.08705292373494693, 'subsample': 0.6428102733478107, 'colsample_bytree': 0.5215604733017689, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:50:57,677] Trial 12 finished with value: 0.8295454545454546 and parameters: {'lambda': 0.11043437329064591, 'alpha': 0.002497555487971469, 'max_depth': 12, 'eta': 0.09977690228650302, 'subsample': 0.6547337088490064, 'colsample_bytree': 0.5242110402421158, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:51:09,689] Trial 13 finished with value: 0.8021978021978022 and parameters: {'lambda': 0.01184367451187412, 'alpha': 0.002720694810745269, 'max_depth': 11, 'eta': 0.10263986735176821, 'subsample': 0.513920779397159, 'colsample_bytree': 0.8235248528246675, 'min_child_weight': 2}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:51:30,799] Trial 14 finished with value: 0.8228571428571428 and parameters: {'lambda': 0.07033447361977954, 'alpha': 0.0010528914842209893, 'max_depth': 14, 'eta': 0.07265161736096737, 'subsample': 0.8170079376766308, 'colsample_bytree': 0.6280962614159845, 'min_child_weight': 3}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:51:47,646] Trial 15 finished with value: 0.8248587570621468 and parameters: {'lambda': 0.5611835403447559, 'alpha': 0.0790003090157209, 'max_depth': 9, 'eta': 0.11248468213471814, 'subsample': 0.6532347587161723, 'colsample_bytree': 0.8013913837673079, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:52:04,889] Trial 16 finished with value: 0.8111111111111111 and parameters: {'lambda': 0.01915481839634712, 'alpha': 0.005659966039459271, 'max_depth': 11, 'eta': 0.07670511355942308, 'subsample': 0.6231774279532604, 'colsample_bytree': 0.6073010594859214, 'min_child_weight': 3}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:52:17,622] Trial 17 finished with value: 0.8287292817679558 and parameters: {'lambda': 0.34774017692643017, 'alpha': 1.9702636146040227, 'max_depth': 7, 'eta': 0.12294470989871552, 'subsample': 0.6800371036314986, 'colsample_bytree': 0.8851454029299278, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:52:34,224] Trial 18 finished with value: 0.8111111111111111 and parameters: {'lambda': 0.06433590656106795, 'alpha': 0.4408808500311748, 'max_depth': 15, 'eta': 0.2002629216662982, 'subsample': 0.5299181143661836, 'colsample_bytree': 0.580424386696515, 'min_child_weight': 2}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:52:46,167] Trial 19 finished with value: 0.8156424581005587 and parameters: {'lambda': 0.008821217702955037, 'alpha': 0.0036533189139146987, 'max_depth': 13, 'eta': 0.1319992979322025, 'subsample': 0.8034679904151154, 'colsample_bytree': 0.7708351455318431, 'min_child_weight': 3}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:53:01,093] Trial 20 finished with value: 0.8176795580110497 and parameters: {'lambda': 1.9715906203601685, 'alpha': 0.039396400850206036, 'max_depth': 10, 'eta': 0.0853896601012119, 'subsample': 0.6047099522847377, 'colsample_bytree': 0.8466975654000702, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:53:19,941] Trial 21 finished with value: 0.8295454545454546 and parameters: {'lambda': 0.12475087977646072, 'alpha': 0.0018599854082210936, 'max_depth': 12, 'eta': 0.09889716868287944, 'subsample': 0.6812611944532088, 'colsample_bytree': 0.5092381525839422, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:53:37,922] Trial 22 finished with value: 0.8228571428571428 and parameters: {'lambda': 0.10100305724739993, 'alpha': 0.005028092257973529, 'max_depth': 12, 'eta': 0.06580178642074344, 'subsample': 0.6725887452789076, 'colsample_bytree': 0.5681005387466699, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:53:56,699] Trial 23 finished with value: 0.8228571428571428 and parameters: {'lambda': 0.03659771490428572, 'alpha': 0.0018278566718849247, 'max_depth': 13, 'eta': 0.09953049725502792, 'subsample': 0.7295933469431793, 'colsample_bytree': 0.5440308250133182, 'min_child_weight': 2}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:54:18,729] Trial 24 finished with value: 0.8248587570621468 and parameters: {'lambda': 0.0017853011132038536, 'alpha': 0.00934353863807857, 'max_depth': 11, 'eta': 0.11775770039565354, 'subsample': 0.63466938948934, 'colsample_bytree': 0.7502267020184947, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:54:32,092] Trial 25 finished with value: 0.8202247191011236 and parameters: {'lambda': 0.8007813217490727, 'alpha': 0.0016034468342349727, 'max_depth': 9, 'eta': 0.08451311972037982, 'subsample': 0.696766468645974, 'colsample_bytree': 0.6506369912029129, 'min_child_weight': 2}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:54:42,973] Trial 26 finished with value: 0.8390804597701149 and parameters: {'lambda': 0.2726713449194312, 'alpha': 0.003477774807879877, 'max_depth': 14, 'eta': 0.1778996646623095, 'subsample': 0.656786738879571, 'colsample_bytree': 0.5840525853108292, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:55:01,168] Trial 27 finished with value: 0.8089887640449438 and parameters: {'lambda': 0.2635742656161999, 'alpha': 0.004604666759660082, 'max_depth': 14, 'eta': 0.18729815774573538, 'subsample': 0.6122202144825561, 'colsample_bytree': 0.5870445083412725, 'min_child_weight': 3}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:55:11,388] Trial 28 finished with value: 0.8323699421965318 and parameters: {'lambda': 0.42011503017661356, 'alpha': 0.012738737675857675, 'max_depth': 14, 'eta': 0.22249277221272895, 'subsample': 0.5680206948794265, 'colsample_bytree': 0.6679489592052279, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:55:19,720] Trial 29 finished with value: 0.8087431693989071 and parameters: {'lambda': 0.7370026476828831, 'alpha': 0.01707733691592698, 'max_depth': 14, 'eta': 0.23190368416178056, 'subsample': 0.5513886220475682, 'colsample_bytree': 0.9062401959779329, 'min_child_weight': 5}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:55:30,911] Trial 30 finished with value: 0.7978142076502732 and parameters: {'lambda': 0.3549213805914938, 'alpha': 0.03626015305784418, 'max_depth': 6, 'eta': 0.16249751339054508, 'subsample': 0.5814290002823852, 'colsample_bytree': 0.6730220789388479, 'min_child_weight': 2}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:55:44,738] Trial 31 finished with value: 0.8268156424581006 and parameters: {'lambda': 1.8552682554532056, 'alpha': 0.009551157081816565, 'max_depth': 15, 'eta': 0.1435793636495326, 'subsample': 0.5019537846201159, 'colsample_bytree': 0.6215851914912895, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:55:49,854] Trial 32 finished with value: 0.8426966292134831 and parameters: {'lambda': 0.1699453445901162, 'alpha': 0.003418069612473324, 'max_depth': 13, 'eta': 0.2988239012586811, 'subsample': 0.7184402558572901, 'colsample_bytree': 0.5545295829179616, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:55:58,689] Trial 33 finished with value: 0.8268156424581006 and parameters: {'lambda': 0.4483618441890233, 'alpha': 0.0067540164172856625, 'max_depth': 14, 'eta': 0.2900494213095255, 'subsample': 0.708614106748232, 'colsample_bytree': 0.731939574708658, 'min_child_weight': 2}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:56:12,481] Trial 34 finished with value: 0.8181818181818182 and parameters: {'lambda': 0.17773964238261766, 'alpha': 0.013575419348065252, 'max_depth': 13, 'eta': 0.22276483661512272, 'subsample': 0.7315401954910337, 'colsample_bytree': 0.7768007285904412, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:56:20,732] Trial 35 finished with value: 0.8295454545454546 and parameters: {'lambda': 0.842088188359611, 'alpha': 0.004364492949928026, 'max_depth': 15, 'eta': 0.2618349705913831, 'subsample': 0.773880678881726, 'colsample_bytree': 0.5602154763967604, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:56:29,389] Trial 36 finished with value: 0.8181818181818182 and parameters: {'lambda': 0.23774808388927585, 'alpha': 0.003268981014542514, 'max_depth': 13, 'eta': 0.24213264329417422, 'subsample': 0.8149863599556918, 'colsample_bytree': 0.6774630165859856, 'min_child_weight': 2}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:56:41,895] Trial 37 finished with value: 0.8275862068965517 and parameters: {'lambda': 1.2521529442538557, 'alpha': 0.023538642369741583, 'max_depth': 14, 'eta': 0.2847371222516766, 'subsample': 0.8709267329760947, 'colsample_bytree': 0.6401808392074304, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:56:51,355] Trial 38 finished with value: 0.8228571428571428 and parameters: {'lambda': 0.5461154920845473, 'alpha': 0.01047593011593444, 'max_depth': 15, 'eta': 0.1631838841017243, 'subsample': 0.7574531947356733, 'colsample_bytree': 0.6056612823639999, 'min_child_weight': 2}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:57:05,888] Trial 39 finished with value: 0.8390804597701149 and parameters: {'lambda': 0.13270813377222912, 'alpha': 0.06513598692866428, 'max_depth': 6, 'eta': 0.1931835643440498, 'subsample': 0.5519619673969764, 'colsample_bytree': 0.6908700607197814, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:57:16,156] Trial 40 finished with value: 0.8066298342541437 and parameters: {'lambda': 0.14463234643937495, 'alpha': 0.09520178018650294, 'max_depth': 6, 'eta': 0.2008053594979193, 'subsample': 0.6999142245992712, 'colsample_bytree': 0.7174917842112579, 'min_child_weight': 2}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:57:33,277] Trial 41 finished with value: 0.8361581920903954 and parameters: {'lambda': 0.07121689589625492, 'alpha': 0.05777371450083807, 'max_depth': 7, 'eta': 0.17852741576382064, 'subsample': 0.550890448570819, 'colsample_bytree': 0.7008344886973575, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:57:47,482] Trial 42 finished with value: 0.8248587570621468 and parameters: {'lambda': 0.07039073711389399, 'alpha': 0.3155493688909589, 'max_depth': 7, 'eta': 0.17681318395399853, 'subsample': 0.5464138197865038, 'colsample_bytree': 0.6964030685099923, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:58:02,786] Trial 43 finished with value: 0.8222222222222222 and parameters: {'lambda': 0.02308919264861392, 'alpha': 0.06013703690383717, 'max_depth': 5, 'eta': 0.1531905791952898, 'subsample': 0.5312242562212648, 'colsample_bytree': 0.7558962028555165, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:58:13,644] Trial 44 finished with value: 0.8248587570621468 and parameters: {'lambda': 0.07632354796627924, 'alpha': 0.14930972988210006, 'max_depth': 8, 'eta': 0.13660344287629414, 'subsample': 0.5856959616722134, 'colsample_bytree': 0.7251434771660226, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:58:24,136] Trial 45 finished with value: 0.8390804597701149 and parameters: {'lambda': 0.18349959956395315, 'alpha': 0.05367785754841743, 'max_depth': 6, 'eta': 0.17889178817724127, 'subsample': 0.7338289205651527, 'colsample_bytree': 0.7900216791547654, 'min_child_weight': 1}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:58:37,853] Trial 46 finished with value: 0.8397790055248618 and parameters: {'lambda': 0.2626049538098244, 'alpha': 0.3000817549365154, 'max_depth': 5, 'eta': 0.19058361595984302, 'subsample': 0.7867962230024681, 'colsample_bytree': 0.79232629757168, 'min_child_weight': 4}. Best is trial 8 with value: 0.847457627118644.\n",
      "[I 2025-08-11 22:58:47,402] Trial 47 finished with value: 0.8539325842696629 and parameters: {'lambda': 0.26087966971093096, 'alpha': 0.6020169282827088, 'max_depth': 5, 'eta': 0.20592723348952346, 'subsample': 0.7881061067931009, 'colsample_bytree': 0.8553806689528791, 'min_child_weight': 4}. Best is trial 47 with value: 0.8539325842696629.\n",
      "[I 2025-08-11 22:58:54,895] Trial 48 finished with value: 0.8108108108108109 and parameters: {'lambda': 0.2680946589357514, 'alpha': 1.0301476706158377, 'max_depth': 5, 'eta': 0.20580582801578517, 'subsample': 0.8465672120012462, 'colsample_bytree': 0.8325125357638001, 'min_child_weight': 4}. Best is trial 47 with value: 0.8539325842696629.\n",
      "[I 2025-08-11 22:59:04,636] Trial 49 finished with value: 0.8379888268156425 and parameters: {'lambda': 1.0985308956457056, 'alpha': 0.9034211838096659, 'max_depth': 5, 'eta': 0.2685935747263522, 'subsample': 0.7879220938967199, 'colsample_bytree': 0.8636732992116178, 'min_child_weight': 4}. Best is trial 47 with value: 0.8539325842696629.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lambda': 0.26087966971093096, 'alpha': 0.6020169282827088, 'max_depth': 5, 'eta': 0.20592723348952346, 'subsample': 0.7881061067931009, 'colsample_bytree': 0.8553806689528791, 'min_child_weight': 4}\n",
      "Best f1 Score: 0.8539325842696629\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_score, f1_score,recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "      \"objective\": \"binary:logistic\",\n",
    "      \"eval_metric\": \"aucpr\",\n",
    "      \"tree_method\": \"hist\",\n",
    "      \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 2, log=True),\n",
    "      \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 2, log=True),\n",
    "      \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15),\n",
    "      \"eta\": trial.suggest_float(\"eta\", 0.05, 0.3, log=True),\n",
    "      \"subsample\": trial.suggest_float(\"subsample\", 0.5, 0.9),\n",
    "      \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "      \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n",
    "      \"scale_pos_weight\": 1\n",
    "    }\n",
    "    #Best hyperparameters: {'lambda': 0.9718397047896502, 'alpha': 9.435569939830177e-09, 'max_depth': 15, 'eta': 0.22073806618552336, 'subsample': 0.5981116119161971, 'colsample_bytree': 0.5428281820554541, 'min_child_weight': 1, 'scale_pos_weight': 4.020635467730019}\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_resampled_ROS, label=y_train_resampled_ROS)\n",
    "    dvalid = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dvalid, \"validation\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    preds = model.predict(dvalid)\n",
    "    preds_binary = (preds > 0.2).astype(int)\n",
    "    recall = f1_score(y_test, preds_binary)\n",
    "    return recall\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best f1 Score:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e389950a",
   "metadata": {},
   "source": [
    "same but diffrent threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1173560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 00:31:11,105] A new study created in memory with name: no-name-16a1a021-c488-4de5-ae4a-23b297ecb38f\n",
      "[I 2025-08-12 00:31:25,444] Trial 0 finished with value: 0.8295454545454546 and parameters: {'lambda': 1.828446144012234, 'alpha': 0.4047733607088958, 'max_depth': 9, 'eta': 0.09485530598158444, 'subsample': 0.6138250923940571, 'colsample_bytree': 0.7530293204804623, 'min_child_weight': 4}. Best is trial 0 with value: 0.8295454545454546.\n",
      "[I 2025-08-12 00:31:38,559] Trial 1 finished with value: 0.8275862068965517 and parameters: {'lambda': 0.01262026227088738, 'alpha': 1.7956607946088479, 'max_depth': 15, 'eta': 0.1497629790520382, 'subsample': 0.5444154994906587, 'colsample_bytree': 0.7261087862674576, 'min_child_weight': 3}. Best is trial 0 with value: 0.8295454545454546.\n",
      "[I 2025-08-12 00:31:52,570] Trial 2 finished with value: 0.8439306358381503 and parameters: {'lambda': 0.05063818280500156, 'alpha': 0.012110589709113757, 'max_depth': 10, 'eta': 0.09925448413993328, 'subsample': 0.7608638313897678, 'colsample_bytree': 0.8956540143238969, 'min_child_weight': 3}. Best is trial 2 with value: 0.8439306358381503.\n",
      "[I 2025-08-12 00:32:00,028] Trial 3 finished with value: 0.8457142857142858 and parameters: {'lambda': 0.0017863448858348333, 'alpha': 0.28044269506326197, 'max_depth': 8, 'eta': 0.22756746672861214, 'subsample': 0.683567015637804, 'colsample_bytree': 0.9271678504824699, 'min_child_weight': 2}. Best is trial 3 with value: 0.8457142857142858.\n",
      "[I 2025-08-12 00:32:14,095] Trial 4 finished with value: 0.8181818181818182 and parameters: {'lambda': 0.012539390942671275, 'alpha': 0.02115111498930329, 'max_depth': 11, 'eta': 0.13687947187357347, 'subsample': 0.5540762949116975, 'colsample_bytree': 0.8713424995647588, 'min_child_weight': 5}. Best is trial 3 with value: 0.8457142857142858.\n",
      "[I 2025-08-12 00:32:24,269] Trial 5 finished with value: 0.8488372093023255 and parameters: {'lambda': 0.0013334160114136465, 'alpha': 0.04750223303391242, 'max_depth': 6, 'eta': 0.13123833490699707, 'subsample': 0.6965442958335472, 'colsample_bytree': 0.8927549635030347, 'min_child_weight': 3}. Best is trial 5 with value: 0.8488372093023255.\n",
      "[I 2025-08-12 00:32:34,772] Trial 6 finished with value: 0.8323699421965318 and parameters: {'lambda': 0.022339277244011572, 'alpha': 0.06786653599161739, 'max_depth': 14, 'eta': 0.09262018772626768, 'subsample': 0.7518358173373958, 'colsample_bytree': 0.506926634954955, 'min_child_weight': 2}. Best is trial 5 with value: 0.8488372093023255.\n",
      "[I 2025-08-12 00:32:45,694] Trial 7 finished with value: 0.8304093567251462 and parameters: {'lambda': 0.0272438830513602, 'alpha': 0.016241658084722842, 'max_depth': 14, 'eta': 0.10989028670207032, 'subsample': 0.8615188016697568, 'colsample_bytree': 0.5363041323358492, 'min_child_weight': 1}. Best is trial 5 with value: 0.8488372093023255.\n",
      "[I 2025-08-12 00:32:51,759] Trial 8 finished with value: 0.8275862068965517 and parameters: {'lambda': 0.4348003389990981, 'alpha': 0.01946311960039828, 'max_depth': 15, 'eta': 0.2271785529462692, 'subsample': 0.703262792670958, 'colsample_bytree': 0.8134370086134631, 'min_child_weight': 4}. Best is trial 5 with value: 0.8488372093023255.\n",
      "[I 2025-08-12 00:33:00,664] Trial 9 finished with value: 0.8390804597701149 and parameters: {'lambda': 0.002810087891420304, 'alpha': 0.12949518048580658, 'max_depth': 11, 'eta': 0.13773219266677816, 'subsample': 0.7731122003301931, 'colsample_bytree': 0.9441895923005128, 'min_child_weight': 2}. Best is trial 5 with value: 0.8488372093023255.\n",
      "[I 2025-08-12 00:33:12,030] Trial 10 finished with value: 0.8216216216216217 and parameters: {'lambda': 0.13681925821749993, 'alpha': 0.002152415117890095, 'max_depth': 5, 'eta': 0.054269899590902664, 'subsample': 0.87823177022254, 'colsample_bytree': 0.6564151723340691, 'min_child_weight': 5}. Best is trial 5 with value: 0.8488372093023255.\n",
      "[I 2025-08-12 00:33:20,855] Trial 11 finished with value: 0.8323699421965318 and parameters: {'lambda': 0.001349469296825751, 'alpha': 0.3499164337724139, 'max_depth': 6, 'eta': 0.2921961767012915, 'subsample': 0.6315383172994854, 'colsample_bytree': 0.997519083556267, 'min_child_weight': 2}. Best is trial 5 with value: 0.8488372093023255.\n",
      "[I 2025-08-12 00:33:30,094] Trial 12 finished with value: 0.8520710059171598 and parameters: {'lambda': 0.0036060948893750816, 'alpha': 0.16548843799385377, 'max_depth': 7, 'eta': 0.19413976410611886, 'subsample': 0.6496746130230838, 'colsample_bytree': 0.9995919465225381, 'min_child_weight': 1}. Best is trial 12 with value: 0.8520710059171598.\n",
      "[I 2025-08-12 00:33:44,153] Trial 13 finished with value: 0.8538011695906432 and parameters: {'lambda': 0.003574564252058108, 'alpha': 0.0018374014945832058, 'max_depth': 7, 'eta': 0.18384908669187353, 'subsample': 0.6118341228820893, 'colsample_bytree': 0.974955235828604, 'min_child_weight': 1}. Best is trial 13 with value: 0.8538011695906432.\n",
      "[I 2025-08-12 00:33:53,225] Trial 14 finished with value: 0.8452380952380952 and parameters: {'lambda': 0.004711031967169475, 'alpha': 0.0014414545094436223, 'max_depth': 7, 'eta': 0.17922132628619994, 'subsample': 0.6027091235234212, 'colsample_bytree': 0.9902304668248786, 'min_child_weight': 1}. Best is trial 13 with value: 0.8538011695906432.\n",
      "[I 2025-08-12 00:34:04,299] Trial 15 finished with value: 0.8554913294797688 and parameters: {'lambda': 0.005759695240451479, 'alpha': 0.0034533900755496327, 'max_depth': 8, 'eta': 0.18258902255991474, 'subsample': 0.5135903178569744, 'colsample_bytree': 0.8205920335534742, 'min_child_weight': 1}. Best is trial 15 with value: 0.8554913294797688.\n",
      "[I 2025-08-12 00:34:12,450] Trial 16 finished with value: 0.8275862068965517 and parameters: {'lambda': 0.006631008287511047, 'alpha': 0.0032345103432331445, 'max_depth': 9, 'eta': 0.2944448967354205, 'subsample': 0.510496684302249, 'colsample_bytree': 0.8190628432745091, 'min_child_weight': 1}. Best is trial 15 with value: 0.8554913294797688.\n",
      "[I 2025-08-12 00:34:28,160] Trial 17 finished with value: 0.8372093023255814 and parameters: {'lambda': 0.007827189865421165, 'alpha': 0.005377239368971252, 'max_depth': 12, 'eta': 0.17398210393513444, 'subsample': 0.5731287119690229, 'colsample_bytree': 0.6238910915294922, 'min_child_weight': 1}. Best is trial 15 with value: 0.8554913294797688.\n",
      "[I 2025-08-12 00:34:48,448] Trial 18 finished with value: 0.8342857142857143 and parameters: {'lambda': 0.061751803484387476, 'alpha': 0.006465419492309707, 'max_depth': 8, 'eta': 0.07039664869853669, 'subsample': 0.5029479415793823, 'colsample_bytree': 0.8223333349929578, 'min_child_weight': 2}. Best is trial 15 with value: 0.8554913294797688.\n",
      "[I 2025-08-12 00:34:56,676] Trial 19 finished with value: 0.8470588235294118 and parameters: {'lambda': 0.15442574363809455, 'alpha': 0.0013115885149968542, 'max_depth': 5, 'eta': 0.23399476081532372, 'subsample': 0.5690914782860889, 'colsample_bytree': 0.7491571700763258, 'min_child_weight': 1}. Best is trial 15 with value: 0.8554913294797688.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'lambda': 0.005759695240451479, 'alpha': 0.0034533900755496327, 'max_depth': 8, 'eta': 0.18258902255991474, 'subsample': 0.5135903178569744, 'colsample_bytree': 0.8205920335534742, 'min_child_weight': 1}\n",
      "Best f1 Score: 0.8554913294797688\n"
     ]
    }
   ],
   "source": [
    "# Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "      \"objective\": \"binary:logistic\",\n",
    "      \"eval_metric\": \"aucpr\",\n",
    "      \"tree_method\": \"hist\",\n",
    "      \"lambda\": trial.suggest_float(\"lambda\", 1e-3, 2, log=True),\n",
    "      \"alpha\": trial.suggest_float(\"alpha\", 1e-3, 2, log=True),\n",
    "      \"max_depth\": trial.suggest_int(\"max_depth\", 5, 15),\n",
    "      \"eta\": trial.suggest_float(\"eta\", 0.05, 0.3, log=True),\n",
    "      \"subsample\": trial.suggest_float(\"subsample\", 0.5, 0.9),\n",
    "      \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "      \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 5),\n",
    "      \"scale_pos_weight\": 1\n",
    "    }\n",
    "    #Best hyperparameters: {'lambda': 0.9718397047896502, 'alpha': 9.435569939830177e-09, 'max_depth': 15, 'eta': 0.22073806618552336, 'subsample': 0.5981116119161971, 'colsample_bytree': 0.5428281820554541, 'min_child_weight': 1, 'scale_pos_weight': 4.020635467730019}\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train_resampled_ROS, label=y_train_resampled_ROS)\n",
    "    dvalid = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dvalid, \"validation\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    preds = model.predict(dvalid)\n",
    "    preds_binary = (preds > 0.6).astype(int)\n",
    "\n",
    "    # We'll optimize for recall score\n",
    "    recall = f1_score(y_test, preds_binary)\n",
    "    return recall\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best f1 Score:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14620fbd",
   "metadata": {},
   "source": [
    "Used XG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2efd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_score, f1_score , accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "params = {\n",
    "    #{'lambda': 0.30320108269541146, 'alpha': 0.006015313447322198,\n",
    "    #  'max_depth': 5, 'eta': 0.2914599585048081, 'subsample': 0.8912722531940445,\n",
    "    #  'colsample_bytree': 0.781007056817272, 'min_child_weight': 1} 0.85 f1 score\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"aucpr\",\n",
    "        \"tree_method\": \"hist\",  # \"gpu_hist\" if GPU available\n",
    "        \"lambda\": 0.30320108269541146,\n",
    "        \"alpha\": 0.006015313447322198,\n",
    "        \"max_depth\": 5,\n",
    "        \"eta\": 0.2914599585048081,\n",
    "        \"subsample\": 0.8912722531940445,\n",
    "        \"colsample_bytree\": 0.781007056817272,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"scale_pos_weight\": 1   # Important for imbalance\n",
    "    }\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train_resampled_ROS, label=y_train_resampled_ROS)\n",
    "dvalid = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "\n",
    "modelXG = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dvalid, \"validation\")],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose_eval=False)\n",
    "\n",
    "\n",
    "preds = modelXG.predict(dvalid)\n",
    "\n",
    "\n",
    "#preds = modelXG.predict(dvalid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215edc81",
   "metadata": {},
   "source": [
    "Best model so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8646f51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8587570621468926\n",
      "0.926829268292683\n",
      "0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.93      0.80      0.86        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.96      0.90      0.93     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "[[56645     6]\n",
      " [   19    76]]\n",
      "0.9995594403129736\n"
     ]
    }
   ],
   "source": [
    "preds_binary = (preds > 0.3).astype(int)\n",
    "\n",
    "print(f1_score(y_test, preds_binary)) \n",
    "print(precision_score(y_test, preds_binary)) \n",
    "print(recall_score(y_test, preds_binary))\n",
    "print(classification_report(y_test, preds_binary))\n",
    "print(confusion_matrix(y_test, preds_binary))\n",
    "print(accuracy_score(y_test, preds_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "38cb44c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud_model.pkl']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(modelXG, \"fraud_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b684a",
   "metadata": {},
   "source": [
    "trying to maxmize recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9dda12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'lambda': 0.005759695240451479, 'alpha': 0.0034533900755496327, 'max_depth': 8,\n",
    "#  'eta': 0.18258902255991474, 'subsample': 0.5135903178569744, \n",
    "# 'colsample_bytree': 0.8205920335534742, 'min_child_weight': 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fada10",
   "metadata": {},
   "source": [
    "random forest on undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e5d34b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for RUS:\n",
      "[[56650     1]\n",
      " [   25    70]]\n",
      "Classification Report for RUS:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.99      0.74      0.84        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.99      0.87      0.92     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "Accuracy for RUS: 0.9995418179254926\n"
     ]
    }
   ],
   "source": [
    "#random forest on undersampled data\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=40,max_depth=50)\n",
    "model.fit(X_train_resampled_ROS, y_train_resampled_ROS)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "y_pred_rus = model.predict(X_test_scaled)\n",
    "print(\"Confusion Matrix for RUS:\")\n",
    "print(confusion_matrix(y_test, y_pred_rus))\n",
    "print(\"Classification Report for RUS:\")\n",
    "print(classification_report(y_test, y_pred_rus))\n",
    "print(\"Accuracy for RUS:\", accuracy_score(y_test, y_pred_rus))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd76013d",
   "metadata": {},
   "source": [
    "TRying to maxmize recall..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de1da8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x13361b9a0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "model = CatBoostClassifier(iterations=800, learning_rate=0.05, depth=10, verbose=0)\n",
    "model.fit(X_train_resampled_ROS, y_train_resampled_ROS)  # Assuming you have identified categorical feature indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f4c09f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56651\n",
      "           1       0.90      0.80      0.85        95\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.95      0.90      0.92     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "Accuracy for RUS: 0.9995241955380115\n"
     ]
    }
   ],
   "source": [
    "y_predCat = model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_predCat ))\n",
    "print(\"Accuracy for RUS:\", accuracy_score(y_test, y_predCat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22534174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud_model_Cat.pkl']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, \"fraud_model_Cat.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1d48805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for RUS:\n",
      "[[55726   925]\n",
      " [   12    83]]\n",
      "Classification Report for RUS:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56651\n",
      "           1       0.08      0.87      0.15        95\n",
      "\n",
      "    accuracy                           0.98     56746\n",
      "   macro avg       0.54      0.93      0.57     56746\n",
      "weighted avg       1.00      0.98      0.99     56746\n",
      "\n",
      "Accuracy for RUS: 0.9834878229302506\n"
     ]
    }
   ],
   "source": [
    "#random forest on undersampled data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "modelRUS=RandomForestClassifier(n_estimators=200,random_state=42)\n",
    "modelRUS.fit(X_train_resampled_rus, y_train_resampled_rus)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "y_pred_rus = modelRUS.predict(X_test_scaled)\n",
    "print(\"Confusion Matrix for RUS:\")\n",
    "print(confusion_matrix(y_test, y_pred_rus))\n",
    "print(\"Classification Report for RUS:\")\n",
    "print(classification_report(y_test, y_pred_rus))\n",
    "print(\"Accuracy for RUS:\", accuracy_score(y_test, y_pred_rus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "210c5ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fraud_model_RF.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(modelRUS, \"fraud_model_RF.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
